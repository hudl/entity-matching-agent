{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dbb8421-5aef-4c1f-8b9b-41d7a31473a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d9fe87c-2caa-4634-bebd-32de6fff20a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-aws\n",
      "  Downloading langchain_aws-0.2.27-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: boto3 in ./venv/lib/python3.13/site-packages (1.38.46)\n",
      "Collecting langchain-core<1.0.0,>=0.3.66 (from langchain)\n",
      "  Downloading langchain_core-0.3.66-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.4.4-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.41-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.13/site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.13/site-packages (from langchain) (6.0.2)\n",
      "Collecting numpy<3,>=1.26.0 (from langchain-aws)\n",
      "  Downloading numpy-2.3.1-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: botocore<1.39.0,>=1.38.46 in ./venv/lib/python3.13/site-packages (from boto3) (1.38.46)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in ./venv/lib/python3.13/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in ./venv/lib/python3.13/site-packages (from boto3) (0.13.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in ./venv/lib/python3.13/site-packages (from botocore<1.39.0,>=1.38.46->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in ./venv/lib/python3.13/site-packages (from botocore<1.39.0,>=1.38.46->boto3) (2.5.0)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.66->langchain)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.66->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<1.0.0,>=0.3.66->langchain)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.18-cp313-cp313-macosx_15_0_arm64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.23.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached pydantic_core-2.33.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2025.6.15)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.13/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.39.0,>=1.38.46->boto3) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "Downloading langchain-0.3.26-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_aws-0.2.27-py3-none-any.whl (121 kB)\n",
      "Downloading langchain_core-0.3.66-py3-none-any.whl (438 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading langsmith-0.4.4-py3-none-any.whl (367 kB)\n",
      "Downloading numpy-2.3.1-cp313-cp313-macosx_14_0_arm64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp313-cp313-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Downloading sqlalchemy-2.0.41-cp313-cp313-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading orjson-3.10.18-cp313-cp313-macosx_15_0_arm64.whl (133 kB)\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading zstandard-0.23.0-cp313-cp313-macosx_11_0_arm64.whl (633 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m633.4/633.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: zstandard, typing-inspection, tenacity, SQLAlchemy, pydantic-core, packaging, orjson, numpy, jsonpatch, annotated-types, requests-toolbelt, pydantic, langsmith, langchain-core, langchain-text-splitters, langchain-aws, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "Successfully installed SQLAlchemy-2.0.41 annotated-types-0.7.0 jsonpatch-1.33 langchain-0.3.26 langchain-aws-0.2.27 langchain-core-0.3.66 langchain-text-splitters-0.3.8 langsmith-0.4.4 numpy-2.3.1 orjson-3.10.18 packaging-24.2 pydantic-2.11.7 pydantic-core-2.33.2 requests-toolbelt-1.0.0 tenacity-9.1.2 typing-inspection-0.4.1 zstandard-0.23.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain langchain-aws boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5f483bc-073a-4647-9d2f-7e0ceb422e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 1. Instantiate the ChatBedrock class\n",
    "# By default, it uses the credentials and region from your environment.\n",
    "llm = ChatBedrock(\n",
    "    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    model_kwargs={\"temperature\": 0.7},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "237195e5-f843-4d3b-9e68-5ed55c2f2f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Large Language Model is an artificial intelligence system trained on vast amounts of text data to understand and generate human-like language for various natural language processing tasks.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(\n",
    "        content=\"Hello! Can you explain what a Large Language Model is in one sentence?\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# 3. Invoke the model\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# 4. Print the response content\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78948b06-040c-4bd6-b27c-2c98ecf77183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS Bedrock offers several benefits, including:\n",
      "\n",
      "1. **Ease of use**: AWS Bedrock simplifies the process of building and deploying LLM-powered applications by providing a unified API and pre-configured models.\n",
      "2. **Cost savings**: AWS Bedrock offers flexible pricing options, allowing customers to pay only for the compute resources they use.\n",
      "3. **Improved performance**: AWS Bedrock is built on AWS's scalable infrastructure, providing fast and reliable access to LLMs.\n",
      "4. **Security and compliance**: AWS Bedrock integrates with AWS's security and compliance features, providing customers with peace of mind when using LLMs.\n",
      "5. **Access to cutting-edge LLMs**: AWS Bedrock provides access to a range of LLMs, including the latest models from leading AI research organizations.\n",
      "\n",
      "Overall, AWS Bedrock provides a convenient and cost-effective way for developers to build and deploy LLM-powered applications, with access to cutting-edge models and AWS's scalable infrastructure.\n"
     ]
    }
   ],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Define the model\n",
    "llm = ChatBedrock(\n",
    "    model_id=\"amazon.titan-text-premier-v1:0\",\n",
    "    model_kwargs={\"temperature\": 0.5}\n",
    ")\n",
    "\n",
    "# Define a prompt template\n",
    "prompt_template = ChatPromptTemplate.from_template(\n",
    "    \"You are a helpful assistant. Answer the following question clearly and concisely.\\nQuestion: {question}\"\n",
    ")\n",
    "\n",
    "# Define an output parser to get the string content from the response\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Create the chain using the | (pipe) operator from LCEL\n",
    "chain = prompt_template | llm | output_parser\n",
    "\n",
    "# Run the chain\n",
    "question = \"What is the primary benefit of using AWS Bedrock?\"\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb010453-6123-40a1-a53c-78c255a1fb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-5.6.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0-cp313-cp313-macosx_14_0_arm64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in ./venv/lib/python3.13/site-packages (from faiss-cpu) (2.3.1)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.13/site-packages (from faiss-cpu) (24.2)\n",
      "Downloading pypdf-5.6.1-py3-none-any.whl (304 kB)\n",
      "Downloading faiss_cpu-1.11.0-cp313-cp313-macosx_14_0_arm64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdf, faiss-cpu\n",
      "Successfully installed faiss-cpu-1.11.0 pypdf-5.6.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pypdf faiss-cpu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93e7e7f0-183b-42e6-a63f-7f8113cfabae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.26-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in ./venv/lib/python3.13/site-packages (from langchain-community) (0.3.66)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in ./venv/lib/python3.13/site-packages (from langchain-community) (0.3.26)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.13/site-packages (from langchain-community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.13/site-packages (from langchain-community) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.13/site-packages (from langchain-community) (6.0.2)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.12.13-cp313-cp313-macosx_11_0_arm64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./venv/lib/python3.13/site-packages (from langchain-community) (9.1.2)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in ./venv/lib/python3.13/site-packages (from langchain-community) (0.4.4)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=2.1.0 in ./venv/lib/python3.13/site-packages (from langchain-community) (2.3.1)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading frozenlist-1.7.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.6.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading propcache-0.3.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading yarl-1.20.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (73 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in ./venv/lib/python3.13/site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.13/site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain-community) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.13/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain-community) (2025.6.15)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.33.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
      "Downloading langchain_community-0.3.26-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.12.13-cp313-cp313-macosx_11_0_arm64.whl (464 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.7.0-cp313-cp313-macosx_11_0_arm64.whl (45 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.6.2-cp313-cp313-macosx_11_0_arm64.whl (43 kB)\n",
      "Downloading propcache-0.3.2-cp313-cp313-macosx_11_0_arm64.whl (41 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.20.1-cp313-cp313-macosx_11_0_arm64.whl (88 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: python-dotenv, propcache, mypy-extensions, multidict, marshmallow, httpx-sse, frozenlist, aiohappyeyeballs, yarl, typing-inspect, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain-community\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.13 aiosignal-1.3.2 dataclasses-json-0.6.7 frozenlist-1.7.0 httpx-sse-0.4.1 langchain-community-0.3.26 marshmallow-3.26.1 multidict-6.6.2 mypy-extensions-1.1.0 propcache-0.3.2 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0 yarl-1.20.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb6196e9-b725-4e4c-b771-1597288ba638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock, BedrockEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 1. Initialize Bedrock LLM and Embeddings model\n",
    "# Note: We use a separate model for creating embeddings (numerical representations of text).\n",
    "llm = ChatBedrock(model_id=\"anthropic.claude-3-haiku-20240307-v1:0\")\n",
    "embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8bc6767-1081-4fa7-8d5f-633cf48b665a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, the main finding mentioned in the document is that the candidate was involved in several projects and initiatives that led to significant improvements in various areas:\n",
      "\n",
      "1. Migrated applications from EC2 to EKS and ECS to EC2, optimizing infrastructure and achieving cost savings of ~$1500/month.\n",
      "\n",
      "2. Streamlined system architecture by merging two closely related bounded contexts into one, reducing database and Kubernetes resource usage by ~50%, leading to significant cost savings and operational efficiency.\n",
      "\n",
      "3. Resolved long-standing customer escalations in legacy paths and channels curation, improving system stability and enhancing customer satisfaction.\n",
      "\n",
      "4. Migrated legacy assessment data to new Kafka event stream, rewriting the backend from Python to Node.js, and redesigning the UI in React using new Figma designs for improved usability.\n",
      "\n",
      "5. Delivered a content tool for assessment questions, automating CSV data processing and integration with assessment Kafka upstream.\n",
      "\n",
      "The document highlights the candidate's technical skills, project management abilities, and contributions to improving system performance, cost efficiency, and customer satisfaction.\n"
     ]
    }
   ],
   "source": [
    "# 2. Load and process your document\n",
    "loader = PyPDFLoader(\"~/Desktop/Personal/Docs/10958-Suraj-Salunke-Resume.pdf\")\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# 3. Create a vector store\n",
    "# This creates vector embeddings and stores them for efficient searching.\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 4. Create a prompt template for the RAG chain\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "# 5. Create the RAG chain\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "# 6. Invoke the chain with a question\n",
    "response = retrieval_chain.invoke({\"input\": \"What was the main finding mentioned in the document?\"})\n",
    "\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2a8605f-f59d-4416-9d4e-804ae17594b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from pydantic import BaseModel, Field\n",
    "import random\n",
    "\n",
    "# --- Tool 1: Get Weather (using @tool decorator for a simple case) ---\n",
    "@tool\n",
    "def get_current_weather(location: str) -> str:\n",
    "    \"\"\"Gets the current weather for a specified location.\"\"\"\n",
    "    if \"mumbai\" in location.lower():\n",
    "        return f\"The weather in {location} is 32°C and sunny.\"\n",
    "    elif \"delhi\" in location.lower():\n",
    "        return f\"The weather in {location} is 35°C with clear skies.\"\n",
    "    else:\n",
    "        return f\"The weather in {location} is {random.randint(25, 35)}°C.\"\n",
    "\n",
    "# --- Tool 2: Get Stock Price (using Pydantic for a more structured schema) ---\n",
    "class StockPriceInput(BaseModel):\n",
    "    ticker_symbol: str = Field(description=\"The stock ticker symbol, e.g., 'AMZN' for Amazon.\")\n",
    "\n",
    "@tool(args_schema=StockPriceInput)\n",
    "def get_stock_price(ticker_symbol: str) -> float:\n",
    "    \"\"\"Gets the current stock price for a given ticker symbol.\"\"\"\n",
    "    # In a real app, you would call an API here.\n",
    "    if ticker_symbol.upper() == \"AMZN\":\n",
    "        return 185.57\n",
    "    elif ticker_symbol.upper() == \"GOOGL\":\n",
    "        return 179.63\n",
    "    else:\n",
    "        return random.uniform(100.0, 500.0)\n",
    "\n",
    "# Create a list of the tools you want the model to have access to\n",
    "tools = [get_current_weather, get_stock_price]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "900aa894-526b-483f-bcf1-0d37c355a263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "# Choose a model that supports tool calling, like Claude 3 Sonnet or Haiku\n",
    "# Haiku is often a great choice for this as it's fast and cost-effective.\n",
    "model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "\n",
    "# Instantiate the model\n",
    "model = ChatBedrock(\n",
    "    model_id=model_id,\n",
    "    model_kwargs={\"temperature\": 0.0}\n",
    ")\n",
    "\n",
    "# Bind the tools to the model\n",
    "# This creates a new model instance that knows about the tools.\n",
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c86a1ffa-6b2e-41b3-af1a-00737173ca12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: What's the weather like in Mumbai?\n",
      "\n",
      "--- Initial Model Response ---\n",
      "content='' additional_kwargs={'usage': {'prompt_tokens': 424, 'completion_tokens': 55, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 479}, 'stop_reason': 'tool_use', 'thinking': {}, 'model_id': 'anthropic.claude-3-haiku-20240307-v1:0', 'model_name': 'anthropic.claude-3-haiku-20240307-v1:0'} response_metadata={'usage': {'prompt_tokens': 424, 'completion_tokens': 55, 'cache_read_input_tokens': 0, 'cache_write_input_tokens': 0, 'total_tokens': 479}, 'stop_reason': 'tool_use', 'thinking': {}, 'model_id': 'anthropic.claude-3-haiku-20240307-v1:0', 'model_name': 'anthropic.claude-3-haiku-20240307-v1:0'} id='run--cc903bbf-4e40-4303-b3d0-1ae91e1b787a-0' tool_calls=[{'name': 'get_current_weather', 'args': {'location': 'Mumbai'}, 'id': 'toolu_bdrk_01Lqe5zuBodMEQhdnUrvDoTH', 'type': 'tool_call'}] usage_metadata={'input_tokens': 424, 'output_tokens': 55, 'total_tokens': 479, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}\n",
      "--------------------\n",
      "Tool Calls: [{'name': 'get_current_weather', 'args': {'location': 'Mumbai'}, 'id': 'toolu_bdrk_01Lqe5zuBodMEQhdnUrvDoTH', 'type': 'tool_call'}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# --- Example 1: A query that should trigger the weather tool ---\n",
    "query1 = \"What's the weather like in Mumbai?\"\n",
    "print(f\"User Query: {query1}\\n\")\n",
    "\n",
    "# The first response from the model will NOT be a final answer.\n",
    "# It will be an instruction to call a tool.\n",
    "ai_response = model_with_tools.invoke([HumanMessage(query1)])\n",
    "\n",
    "print(\"--- Initial Model Response ---\")\n",
    "print(ai_response)\n",
    "print(\"-\" * 20)\n",
    "# This will print an AIMessage containing tool_calls, like:\n",
    "# AIMessage(\n",
    "#   content='',\n",
    "#   additional_kwargs={...},\n",
    "#   response_metadata={...},\n",
    "#   tool_calls=[{\n",
    "#       'name': 'get_current_weather',\n",
    "#       'args': {'location': 'Mumbai'},\n",
    "#       'id': 'tool_call_abc123'\n",
    "#   }]\n",
    "# )\n",
    "\n",
    "# The AIMessage object has a .tool_calls attribute which is a list of parsed tool calls\n",
    "print(f\"Tool Calls: {ai_response.tool_calls}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb2452e9-0823-483c-a9f4-d40e02ea192e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Executing Tool ---\n",
      "Running: get_current_weather({'location': 'Mumbai'})\n",
      "Output: The weather in Mumbai is 32°C and sunny.\n",
      "\n",
      "--- Final Model Response ---\n",
      "The current weather in Mumbai is 32°C and sunny.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "# Now we need to manually execute the tool and return the result\n",
    "# In a real app, this would be a loop over all tool_calls.\n",
    "tool_call = ai_response.tool_calls[0]\n",
    "tool_name = tool_call['name']\n",
    "tool_args = tool_call['args']\n",
    "tool_call_id = tool_call['id']\n",
    "\n",
    "# Find and run the actual Python function\n",
    "if tool_name == \"get_current_weather\":\n",
    "    tool_output = get_current_weather.invoke(tool_args)\n",
    "elif tool_name == \"get_stock_price\":\n",
    "    tool_output = get_stock_price.invoke(tool_args)\n",
    "\n",
    "print(\"--- Executing Tool ---\")\n",
    "print(f\"Running: {tool_name}({tool_args})\")\n",
    "print(f\"Output: {tool_output}\\n\")\n",
    "# Output:\n",
    "# Running: get_current_weather({'location': 'Mumbai'})\n",
    "# Output: The weather in Mumbai is 32°C and sunny.\n",
    "\n",
    "# --- Now, call the model AGAIN with the tool's output ---\n",
    "# We append the original AI message and the new ToolMessage to the history\n",
    "messages = [\n",
    "    HumanMessage(query1),\n",
    "    ai_response, # The message containing the tool call instruction\n",
    "    ToolMessage(content=str(tool_output), tool_call_id=tool_call_id)\n",
    "]\n",
    "\n",
    "final_response = model_with_tools.invoke(messages)\n",
    "\n",
    "print(\"--- Final Model Response ---\")\n",
    "print(final_response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
